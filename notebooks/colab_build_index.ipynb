{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GH_7MoF4SZLf"
   },
   "outputs": [],
   "source": [
    "!pip install -q sentence-transformers faiss-cpu boto3 fastapi uvicorn[standard] nest_asyncio pyngrok requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "PjkOPRcaSjb3",
    "outputId": "b6df98b4-17e0-4861-fd0d-ab8e63eb2ea6"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()  # selecione o arquivo cars.json do seu PC\n",
    "\n",
    "import json\n",
    "fname = list(uploaded.keys())[0]\n",
    "with open(fname, 'r', encoding='utf-8') as f:\n",
    "    cars = json.load(f)\n",
    "\n",
    "print(f\"Arquivo carregado: {fname}, registros: {len(cars)}\")\n",
    "# visualiza os primeiros 2\n",
    "from pprint import pprint\n",
    "pprint(cars[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NmyjaZdbSuGO",
    "outputId": "60b7d10c-fefe-4e0a-8c45-10b782c817fd"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def parse_price(p):\n",
    "    if p is None:\n",
    "        return None\n",
    "    if isinstance(p, (int, float)):\n",
    "        return float(p)\n",
    "    s = str(p)\n",
    "    s = s.replace('R$','').replace('r$','').replace(' ','')\n",
    "    # troca separador de milhar e decimal: assume formato BR \"123.456,78\" ou \"123456.78\"\n",
    "    s = s.replace('.','').replace(',','.')\n",
    "    m = re.search(r'(\\d+(\\.\\d+)?)', s)\n",
    "    if m:\n",
    "        return float(m.group(1))\n",
    "    return None\n",
    "\n",
    "for c in cars:\n",
    "    c['Price'] = parse_price(c.get('Price', None))\n",
    "    # garante chaves mínimas\n",
    "    for k in ['Name','Model','Image','Location']:\n",
    "        if k not in c: c[k] = \"\"\n",
    "\n",
    "print(\"Amostra após normalização:\")\n",
    "from pprint import pprint\n",
    "pprint(cars[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208,
     "referenced_widgets": [
      "c6f0e0c6827a4add9dfa940c9ef5f468",
      "e1c5d30cf94a46708018fdc11b78e955",
      "62d7c17ff00d4ae3812b66e63f9dfbf0",
      "ff13e3d58d4c4ecc90e521b761a0d4c5",
      "7ad62b4d1c124a5d8ea9408012de2b22",
      "9ca6674cdacd4153871f052c4bdb71f7",
      "d267020898fc4cc797446c9dd1d24138",
      "61b15212a73e4cbab7b417a8d78d4994",
      "d0d9222cc3dc4518a92110813dcfdeeb",
      "501ac0f905cf4c19ac1862e33c11da52",
      "bd1af75f94c7442bb5120b91a113acf6"
     ]
    },
    "id": "qV1a_5b7SxKt",
    "outputId": "babe1811-293d-450c-8b34-38cf99aa00fe"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # rápido e pequeno — ótimo pra demo\n",
    "\n",
    "# montar o texto que será embeddado (você pode ajustar: incluir descrições, ano, etc.)\n",
    "texts = []\n",
    "for c in cars:\n",
    "    price_str = f\"R${int(c['Price'])}\" if c.get('Price') else \"\"\n",
    "    texts.append(f\"{c.get('Name','')} {c.get('Model','')} {c.get('Location','')} {price_str}\")\n",
    "\n",
    "print(\"Gerando embeddings (pode demorar alguns segundos dependendo do dataset)...\")\n",
    "embeddings = model.encode(texts, show_progress_bar=True, convert_to_numpy=True)\n",
    "print(\"Embeddings gerados. shape:\", embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RLbop-BbS1qW",
    "outputId": "aa7be1a8-80e8-4932-b445-452cccf88de0"
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "d = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(d)   # índice simples e sem treinamento (ok para datasets pequenos)\n",
    "index.add(embeddings)\n",
    "print(\"Índice FAISS criado. Número de vetores:\", index.ntotal)\n",
    "\n",
    "# salvar index e metadados localmente\n",
    "faiss.write_index(index, 'cars.index')\n",
    "np.save('cars_emb.npy', embeddings)\n",
    "import json\n",
    "with open('cars_meta.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(cars, f, ensure_ascii=False)\n",
    "print(\"Arquivos salvos: cars.index, cars_emb.npy, cars_meta.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3JGg7aVVS8Bx",
    "outputId": "d9de1c8e-f803-4d04-9a30-2ccea6b44fc2"
   },
   "outputs": [],
   "source": [
    "# já temos `index`, `model` e `cars` na memória do notebook\n",
    "def search_text(query, k=5):\n",
    "    q_emb = model.encode([query], convert_to_numpy=True)\n",
    "    D, I = index.search(q_emb, k)\n",
    "    results = []\n",
    "    for dist, idx in zip(D[0], I[0]):\n",
    "        car = cars[idx].copy()\n",
    "        car['score'] = float(dist)   # distância L2 (menor = mais perto)\n",
    "        results.append(car)\n",
    "    return results\n",
    "\n",
    "# exemplo de teste\n",
    "q = \"BYD Dolphin São Paulo 100000\"\n",
    "res = search_text(q, k=5)\n",
    "from pprint import pprint\n",
    "pprint(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90JGRSdYTO-3",
    "outputId": "dbe9726e-2138-4556-d175-803e5bd4741f"
   },
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "# app.py\n",
    "import os, json, time, requests\n",
    "from typing import Optional\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Optional OpenAI - se quiser usar LLM remoto para gerar respostas (RAG)\n",
    "USE_OPENAI = bool(os.getenv(\"OPENAI_API_KEY\"))\n",
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")  # exemplo, troque se desejar\n",
    "\n",
    "if USE_OPENAI:\n",
    "    import openai\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# optional n8n webhook to log events (set N8N_WEBHOOK_URL env var)\n",
    "N8N_WEBHOOK = os.getenv(\"N8N_WEBHOOK_URL\")\n",
    "\n",
    "# load FAISS index and metadata\n",
    "INDEX_PATH = os.getenv(\"INDEX_PATH\", \"cars.index\")\n",
    "META_PATH = os.getenv(\"META_PATH\", \"cars_meta.json\")\n",
    "\n",
    "print(\"Loading index:\", INDEX_PATH)\n",
    "index = faiss.read_index(INDEX_PATH)\n",
    "with open(META_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    cars = json.load(f)\n",
    "print(\"Loaded cars:\", len(cars))\n",
    "\n",
    "# sentence transformer model (same used to build index)\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "app = FastAPI(title=\"Car Search + Chat (RAG)\")\n",
    "\n",
    "def embed_text(texts):\n",
    "    return embed_model.encode(texts, convert_to_numpy=True)\n",
    "\n",
    "def log_event(payload):\n",
    "    # tries n8n webhook if configured\n",
    "    try:\n",
    "        if N8N_WEBHOOK:\n",
    "            requests.post(N8N_WEBHOOK, json=payload, timeout=5)\n",
    "    except Exception as e:\n",
    "        print(\"Failed to send to n8n:\", e)\n",
    "\n",
    "class SearchQuery(BaseModel):\n",
    "    q: Optional[str] = \"\"\n",
    "    k: Optional[int] = 5\n",
    "    location: Optional[str] = None\n",
    "    minPrice: Optional[float] = None\n",
    "    maxPrice: Optional[float] = None\n",
    "\n",
    "@app.post(\"/search\")\n",
    "def search(qobj: SearchQuery):\n",
    "    q = (qobj.q or \"\").strip()\n",
    "    k = qobj.k or 5\n",
    "\n",
    "    # embed + retrieve when q provided (semantic search)\n",
    "    if q:\n",
    "        qe = embed_text([q])\n",
    "        D, I = index.search(qe, k)\n",
    "        results = []\n",
    "        for dist, idx in zip(D[0], I[0]):\n",
    "            item = cars[idx].copy()\n",
    "            item[\"score\"] = float(dist)\n",
    "            results.append(item)\n",
    "    else:\n",
    "        # if no query, return top-k by price ascending as default\n",
    "        results = sorted(cars, key=lambda x: x.get(\"Price\", 1e12))[:k]\n",
    "\n",
    "    # apply filters if present\n",
    "    if qobj.location:\n",
    "        results = [r for r in results if r.get(\"Location\",\"\").lower() == qobj.location.lower()]\n",
    "    if qobj.minPrice:\n",
    "        results = [r for r in results if r.get(\"Price\") is not None and r[\"Price\"] >= float(qobj.minPrice)]\n",
    "    if qobj.maxPrice:\n",
    "        results = [r for r in results if r.get(\"Price\") is not None and r[\"Price\"] <= float(qobj.maxPrice)]\n",
    "\n",
    "    # fallback suggestion: if no results, suggest closest by price\n",
    "    if len(results) == 0 and qobj.maxPrice:\n",
    "        try:\n",
    "            target = float(qobj.maxPrice)\n",
    "            results = sorted(cars, key=lambda a: abs((a.get(\"Price\") or 0) - target))[:5]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # log event (non-blocking best-effort)\n",
    "    try:\n",
    "        log_event({\n",
    "            \"type\": \"search\",\n",
    "            \"query\": q,\n",
    "            \"filters\": {\"location\": qobj.location, \"minPrice\": qobj.minPrice, \"maxPrice\": qobj.maxPrice},\n",
    "            \"resultCount\": len(results),\n",
    "            \"ts\": int(time.time())\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(\"log error\", e)\n",
    "\n",
    "    return {\"results\": results}\n",
    "\n",
    "class ChatQuery(BaseModel):\n",
    "    message: str\n",
    "    k: Optional[int] = 5\n",
    "\n",
    "@app.post(\"/chat\")\n",
    "def chat(c: ChatQuery):\n",
    "    user_message = c.message\n",
    "    k = c.k or 5\n",
    "\n",
    "    # embed + retrieve top-k\n",
    "    q_emb = embed_text([user_message])\n",
    "    D, I = index.search(q_emb, k)\n",
    "    retrieved = []\n",
    "    for j, idx in enumerate(I[0]):\n",
    "        item = cars[idx].copy()\n",
    "        item[\"score\"] = float(D[0][j])\n",
    "        retrieved.append(item)\n",
    "\n",
    "    # Format context\n",
    "    context_lines = []\n",
    "    for r in retrieved:\n",
    "        price = r.get(\"Price\")\n",
    "        price_str = f\"R${int(price):,}\".replace(\",\", \".\") if price else \"N/A\"\n",
    "        context_lines.append(f\"- {r.get('Name')} {r.get('Model')} — {price_str} — {r.get('Location')}\")\n",
    "\n",
    "    context = \"\\n\".join(context_lines)\n",
    "\n",
    "    # If no OpenAI key -> return a templated answer\n",
    "    if not USE_OPENAI:\n",
    "        answer = f\"Encontrei {len(retrieved)} veículos relevantes:\\n{context}\\n\\nSe quiser, posso filtrar por cidade ou preço.\"\n",
    "        log_event({\"type\":\"chat\",\"message\":user_message,\"answer\":answer,\"results_count\":len(retrieved),\"ts\":int(time.time())})\n",
    "        return {\"answer\": answer, \"results\": retrieved}\n",
    "\n",
    "    # Build prompt for the LLM\n",
    "    system_prompt = (\n",
    "        \"Você é um assistente conciso para busca de carros. Use os trechos abaixo (do inventário) para responder a intenção do usuário. \"\n",
    "        \"Se o orçamento do usuário for menor que os preços disponíveis, sugira alternativas, negociações ou opções similares. \"\n",
    "        \"Se o usuário pedir localidade, destaque veículos na localidade e, caso não haja, sugira alternativas em outras cidades com justificativa.\"\n",
    "    )\n",
    "    user_prompt = f\"Inventário relevante:\\n{context}\\n\\nUsuário: \\\"{user_message}\\\"\\nResponda de forma objetiva (máx 200 palavras) e sugira 3 ações (ex: contatar vendedor, salvar alerta, ver similares).\"\n",
    "\n",
    "    # call OpenAI ChatCompletion (exemplo)\n",
    "    try:\n",
    "        resp = openai.ChatCompletion.create(\n",
    "            model=OPENAI_MODEL,\n",
    "            messages=[\n",
    "                {\"role\":\"system\",\"content\":system_prompt},\n",
    "                {\"role\":\"user\",\"content\":user_prompt}\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "            max_tokens=450,\n",
    "        )\n",
    "        answer = resp[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    except Exception as e:\n",
    "        answer = f\"Erro ao acessar LLM: {e}. Exibindo resultados brutos:\\n{context}\"\n",
    "\n",
    "    # log chat event\n",
    "    log_event({\"type\":\"chat\",\"message\":user_message,\"answer\":answer,\"results_count\":len(retrieved),\"ts\":int(time.time())})\n",
    "    return {\"answer\": answer, \"results\": retrieved}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AEWOvzzlPyDP"
   },
   "outputs": [],
   "source": [
    "!fuser -n tcp -k 8000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PaWTtGlrPeeH",
    "outputId": "ccedbeb7-bc0e-4919-be75-0151c9bd24e1"
   },
   "outputs": [],
   "source": [
    "# Baixa o binário oficial mais recente\n",
    "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
    "\n",
    "# Instala o .deb\n",
    "!dpkg -i cloudflared-linux-amd64.deb\n",
    "\n",
    "# Confere se instalou\n",
    "!cloudflared --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1PXXMVlgPf50"
   },
   "outputs": [],
   "source": [
    "import uvicorn, threading\n",
    "\n",
    "def run():\n",
    "    uvicorn.run(\"app:app\", host=\"0.0.0.0\", port=8000)\n",
    "\n",
    "t = threading.Thread(target=run, daemon=True)\n",
    "t.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XEBlXSegPigO",
    "outputId": "79fd6dae-32a3-432b-8528-57396a9825e4"
   },
   "outputs": [],
   "source": [
    "!cloudflared tunnel --url http://localhost:8000 --no-autoupdate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6KlrgEjHPojn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "501ac0f905cf4c19ac1862e33c11da52": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61b15212a73e4cbab7b417a8d78d4994": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62d7c17ff00d4ae3812b66e63f9dfbf0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61b15212a73e4cbab7b417a8d78d4994",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d0d9222cc3dc4518a92110813dcfdeeb",
      "value": 1
     }
    },
    "7ad62b4d1c124a5d8ea9408012de2b22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ca6674cdacd4153871f052c4bdb71f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd1af75f94c7442bb5120b91a113acf6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c6f0e0c6827a4add9dfa940c9ef5f468": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e1c5d30cf94a46708018fdc11b78e955",
       "IPY_MODEL_62d7c17ff00d4ae3812b66e63f9dfbf0",
       "IPY_MODEL_ff13e3d58d4c4ecc90e521b761a0d4c5"
      ],
      "layout": "IPY_MODEL_7ad62b4d1c124a5d8ea9408012de2b22"
     }
    },
    "d0d9222cc3dc4518a92110813dcfdeeb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d267020898fc4cc797446c9dd1d24138": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e1c5d30cf94a46708018fdc11b78e955": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ca6674cdacd4153871f052c4bdb71f7",
      "placeholder": "​",
      "style": "IPY_MODEL_d267020898fc4cc797446c9dd1d24138",
      "value": "Batches: 100%"
     }
    },
    "ff13e3d58d4c4ecc90e521b761a0d4c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_501ac0f905cf4c19ac1862e33c11da52",
      "placeholder": "​",
      "style": "IPY_MODEL_bd1af75f94c7442bb5120b91a113acf6",
      "value": " 1/1 [00:00&lt;00:00,  3.95it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
